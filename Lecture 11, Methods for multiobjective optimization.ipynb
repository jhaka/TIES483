{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 11, Methods for multiobjective optimization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know more about the topic of this lecture, I urge you to read Professor Miettinen's book Nonlinear Multiobjective Optimization\n",
    "\n",
    "![Nonlinear Multiobjective Optimization](images/Miettinen2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification of methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods for multiobjective optimization are often characterized by the involvement of the decision maker in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The types of methods are\n",
    "* **no preference methods**, where the decision maker does not play a role,\n",
    "* **a priori methods**, where the decision maker gives his/her preference information at first and then the optimization method find the best match to that preference information,\n",
    "* **a posteriori methods**, where the optimization methods try to characterize all/find a good represenatation of the Pareto optimal solutions and the decision maker chooses the most preferred one of those,\n",
    "* **interactive methods**, where the optimization method and the decision maker alternate in iteratively search for the most preferred solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Criteria Decision Making (MCDM)\n",
    "* The related researdch field is called multiple criteria decision making\n",
    "* More information in the website of the <a href=\"http://www.mcdmsociety.org/\">International Society on MCDM</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Our example problem for this lecture\n",
    "\n",
    "We study a hypothetical decision problem of buying a car, when you can choose to have a car with power between (denoted by $p$) 50 and 200 kW and average consumption (denoted by $c$) per 100 km between 3 and 10 l. However, in addition to the average consumption and power, you need to decide the volume of the cylinders (v), which may be between 1000 $cm^3$ and $4000cm^3$. Finally, the price of the car follows now a function \n",
    "$$\n",
    "\\left(\\sqrt{\\frac{p-50}{50}}\\\\\n",
    "+\\left(\\frac{p-50}{50}\\right)^2+0.3(10-c)\\\\ +10^{-5}\\left(v-\\left(1000+3000\\frac{p-50}{150}\\right)\\right)^2\\right)10000\\\\+5000\n",
    "$$\n",
    "in euros. This problem can be formulated as a multiobjective optimization problem\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min \\quad & \\{c,-p,P\\},\\\\\n",
    "\\text{s.t. }\\quad\n",
    "&50\\leq p\\leq 200\\\\\n",
    "&3\\leq c\\leq 10\\\\\n",
    "&1000\\leq v\\leq 4000,\\\\\n",
    "\\text{where }\\quad&P = \\left(\\sqrt{\\frac{p-50}{50}}+\\left(\\frac{p-50}{50}\\right)^2+0.3(10-c)\\right.\\\\\n",
    "& \\left.+ 10^{-5}\\left(v-\\left(1000+3000\\frac{p-50}{150}\\right)\\right)^2\\right)10000+5000\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Let us define a Python function which returns the value of this\n",
    "import math\n",
    "def car_problem(c,p,v):\n",
    "#    import pdb; pdb.set_trace()\n",
    "    return [#Objective function values\n",
    "        c,-p,\n",
    "        (math.sqrt((p-50.)/50.)+((p-50.)/50.)**2+\n",
    "        0.3*(10.-c)+0.00001*(v-(1000.+3000.*(p-50.)/150.))**2)*10000.\n",
    "        +5000.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Car with 3 l/100km consumption, 50kW and 1000cm^3 engine would cost \"\n",
    "      +str(car_problem(3,50,1000)[2])+\"€\")\n",
    "print(\"Car with 3 l/100km consumption, 100kW and 2000cm^3 engine would cost \"\n",
    "      +str(car_problem(3,100,2000)[2])+\"€\")\n",
    "print(\"Car with 3 l/100km consumption, 100kW and 1000cm^3 engine would cost \"\n",
    "      +str(car_problem(3,100,1000)[2])+\"€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normalization of the objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In many of the methods, the normalization of the objectives is necessary. **\n",
    "\n",
    "We can normalize the objectives using the nadir and ideal and setting the normalized objective as\n",
    "$$ \\tilde f_i = \\frac{f_i-z_i^{ideal}}{z_i^{nadir}-z_i^{ideal}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calculating the ideal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the ideal for problems is usually easy, if you can optimize the objective functions separately.**\n",
    "\n",
    "For the car problem, ideal can be computed easily using the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculating the ideal\n",
    "from scipy.optimize import minimize\n",
    "import ad\n",
    "def calc_ideal(f):\n",
    "    ideal = [0]*3 #Because three objectives\n",
    "    solutions = [] #list for storing the actual solutions, which give the ideal\n",
    "    bounds = ((3,10),(50,200),(1000,4000)) #Bounds of the problem\n",
    "    for i in range(3):\n",
    "        res=minimize(\n",
    "            #Minimize each objective at the time\n",
    "            lambda x: f(x[0],x[1],x[2])[i], [3,50,1000], method='SLSQP'\n",
    "            #Jacobian using automatic differentiation\n",
    "            ,jac=ad.gh(lambda x: f(x[0],x[1],x[2])[i])[0]\n",
    "            #bounds given above\n",
    "            ,bounds = bounds\n",
    "            ,options = {'disp':True, 'ftol': 1e-20, 'maxiter': 1000})\n",
    "        solutions.append(f(res.x[0],res.x[1],res.x[2]))\n",
    "        ideal[i]=res.fun\n",
    "    return ideal,solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ideal, solutions= calc_ideal(car_problem)\n",
    "print (\"ideal is \"+str(ideal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pay-off table method\n",
    "\n",
    "**Finding the nadir value is however, usually much harder.**\n",
    "\n",
    "Usually, the nadir value is estimated using the so-called pay-off table method.\n",
    "\n",
    "The pay-off table method does not guarantee to find the nadir for problems with more than two objectives. <!--(One of your exercises this week will be to show this.)--> \n",
    "\n",
    "The method is, however, a generally accepted way of approximating the nadir vector.\n",
    "\n",
    "In the pay-off table method:\n",
    "1. the objective values for attaining the individual minima are added in table\n",
    "2. the nadir is estimated by each objectives maxima in the table.\n",
    "3. the ideal values are located in the diagonal of the pay-off table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The nadir for the car selection problem\n",
    "The table now becomes by using the *solutions* that we returned while calculating the ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for solution in solutions:\n",
    "    print solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Thus, the esimation of the nadir vector is \n",
    "$$(10,-50,1033888.543820).$$\n",
    "\n",
    "This is actually the real Nadir vector for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Normalized car problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Let us define a Python function which returns the value of this\n",
    "import math\n",
    "def car_problem_normalized(c,p,v):\n",
    "    z_ideal = [3.0, -200.0, 5000]\n",
    "    z_nadir = [10,-50,1033320.5080756888]\n",
    "#    import pdb; pdb.set_trace()\n",
    "    z = car_problem(c,p,v) \n",
    "    return [(zi-zideali)/(znadiri-zideali) for \n",
    "            (zi,zideali,znadiri) in zip(z,z_ideal,z_nadir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://docs.python.org/3.3/library/functions.html#zip\">the zip function</a> in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Normalized value of the car problem at (3,50,1000) is \"\n",
    "      +str(car_problem_normalized(3,50,1000)))\n",
    "print(\"Normalized value of the car problem at (3,125,2500) is \"\n",
    "      +str(car_problem_normalized(3,125,2500)))\n",
    "print(\"Normalized value of the car problem at (10,100,1000) is \"\n",
    "      +str(car_problem_normalized(10,100,1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** So, value 1 now indicates the worst value on the Pareto frontier and value 0 indicates the best values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the ideal and nadir for later reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_ideal = [3.0, -200.0, 5000]\n",
    "z_nadir = [10.,-50,1033320.5080756888]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From now on, we will deal with the normalized problem, although, we write just $f$.** The aim of this is to simplify presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## No preference methods\n",
    "\n",
    "* Usually only for situations, where the decision maker is not available or does not want to get involved\n",
    "* These just compute a single Pareto optimal solution, which is in somehow mathematically thought as the best compromise\n",
    "\n",
    "## Notation\n",
    "\n",
    "For short, let us denote the feasible set $\\{x\\in\\mathbb R^n: g_j(x) \\geq 0 \\text{ for all }j=1,\\ldots,J \\text{ and } h_k(x) = 0\\text{ for all }k=1,\\ldots,K\\}$ by $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Method of Global criterion\n",
    "\n",
    "Involved minimization of the p-norm of $f(x)-z^{ideal}$, that is we solve the problem\n",
    "$$\n",
    "\\min_{x\\in S} \\|f(x) - z^{ideal}\\|_p.\n",
    "$$\n",
    "\n",
    "![alt text](images/mgc.svg \"Method of global criterion\")\n",
    "\n",
    "**An optimal solution to this problem is Pareto optimal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Applying to our problem studied\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def global_criterion_method(f,p):\n",
    "    #Ideal for any normalized problem is (0,0,0)\n",
    "    ideal = [0,0,0]\n",
    "    bounds = ((3,10),(50,200),(1000,4000)) #Bounds of the problem\n",
    "    #Objective is the norm of objective function values minus\n",
    "    #the ideal\n",
    "    obj = lambda x: np.linalg.norm(np.array(f(x[0],x[1],x[2]))\n",
    "                                   -np.array(ideal),ord=p)\n",
    "    res=minimize(\n",
    "            #Minimize p distance from the ideal\n",
    "            obj, [3,50,1000], method='SLSQP'\n",
    "            #Jacobian using automatic differentiation\n",
    "            ,jac=ad.gh(obj)[0]\n",
    "            #bounds given above\n",
    "            ,bounds = bounds,options = {'disp':True})\n",
    "    return res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solution = global_criterion_method(car_problem_normalized,\n",
    "                                           2)\n",
    "print \"variable values are \",solution\n",
    "f_global_criterion = car_problem(solution[0],solution[1],solution[2])\n",
    "print \"objective values are \",f_global_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help (np.linalg.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solution = global_criterion_method(car_problem_normalized,\n",
    "                                           np.inf)\n",
    "print \"variable values are \",solution\n",
    "f_global_criterion = car_problem(solution[0],solution[1],solution[2])\n",
    "print \"objective values are \",f_global_criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A posteriori methods\n",
    "\n",
    "* A posteriori methods generate a representation of the Pareto optimal solutions, or the complete set of Pareto optimal solutions\n",
    "* Benefits\n",
    "  * The solutions can be visualized for problems with 2 or 3 objectives so the decision making is possible\n",
    "  * When succesful, they give an understanding of the Pareto front\n",
    "* Drawbacks\n",
    "  * Approximating the Pareto optimal set often time-consuming\n",
    "  * Decision making from a large representation may be very difficut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### The weighting method\n",
    "\n",
    "Based on solving optimization problem\n",
    "$$\n",
    "\\min_{x\\in S} \\sum_{i=1}^kw_if_i(x)\n",
    "$$\n",
    "for different weights $w_i\\geq0$, $i=1,\\ldots,k$ such that $\\sum_{i=1}^k w_i=1$. \n",
    "\n",
    "**The idea is to generate weights evenly and then have evenly spread solutions.**\n",
    "\n",
    "**An optimal solution the weighted problem is Pareto optimal, if all the weights $w_i$ are $>0$.**\n",
    "\n",
    "![alt text](images/ws.svg \"Weighting method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Application to our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def weighting_method(f,w):\n",
    "    points = []\n",
    "    bounds = ((3,10),(50,200),(1000,4000)) #Bounds of the problem\n",
    "    for wi in w:\n",
    "        res=minimize(\n",
    "            #weighted sum\n",
    "            lambda x: sum(np.array(wi)*np.array(f(x[0],x[1],x[2]))), \n",
    "            [3,50,1000], method='SLSQP'\n",
    "            #Jacobian using automatic differentiation\n",
    "            ,jac=ad.gh(lambda x: sum(np.array(wi)*np.array(f(x[0],x[1],x[2]))))[0]\n",
    "            #bounds given above\n",
    "            ,bounds = bounds,options = {'disp':False})\n",
    "        points.append(res.x)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = np.random.random((500,3)) #500 random weights\n",
    "repr = weighting_method(car_problem_normalized,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "f_repr_ws = [car_problem(repri[0],repri[1],repri[2]) for repri in repr]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter([f[0] for f in f_repr_ws],[f[1] for f in f_repr_ws],[f[2] for f in f_repr_ws])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
